{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Regularization paths for the Graphical Lasso and its Adaptive variation\nThis example demonstrates how non-convex penalties in the Adaptive Graphical Lasso\ncan achieve superior sparsity recovery compared to the standard L1 penalty.\n\nThe Adaptive Graphical Lasso uses iterative reweighting to approximate non-convex\npenalties, following Cand\u00e8s et al. (2007). Non-convex penalties often produce\nbetter sparsity patterns by more aggressively shrinking small coefficients while\npreserving large ones.\n\nWe compare three approaches:\n    - **L1**: Standard Graphical Lasso with L1 penalty\n    - **Log**: Adaptive approach with logarithmic penalty\n    - **L0.5**: Adaptive approach with L0.5 penalty\n\nThe plots show normalized mean square error (NMSE) for reconstruction accuracy\nand F1 score for sparsity pattern recovery across different regularization levels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Can Pouliquen\n#          Mathurin Massias\n#          Florian Kozikowski\n\nimport numpy as np\nfrom numpy.linalg import norm\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score\n\nfrom skglm.covariance import GraphicalLasso, AdaptiveGraphicalLasso\nfrom skglm.penalties.separable import LogSumPenalty, L0_5\nfrom skglm.utils.data import make_dummy_covariance_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate synthetic sparse precision matrix data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "p = 100\nn = 1000\nS, _, Theta_true, alpha_max = make_dummy_covariance_data(n, p)\nalphas = alpha_max*np.geomspace(1, 1e-4, num=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup models with different penalty functions\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "penalties = [\"L1\", \"Log\", \"L0.5\"]\nn_reweights = 5  # Number of adaptive reweighting iterations\nmodels_tol = 1e-4\n\nmodels = [\n    # Standard Graphical Lasso with L1 penalty\n    GraphicalLasso(algo=\"primal\", warm_start=True, tol=models_tol),\n\n    # Adaptive Graphical Lasso with logarithmic penalty\n    AdaptiveGraphicalLasso(warm_start=True,\n                           penalty=LogSumPenalty(alpha=1.0, eps=1e-10),\n                           n_reweights=n_reweights,\n                           tol=models_tol),\n\n    # Adaptive Graphical Lasso with L0.5 penalty\n    AdaptiveGraphicalLasso(warm_start=True,\n                           penalty=L0_5(alpha=1.0),\n                           n_reweights=n_reweights,\n                           tol=models_tol),\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute regularization paths\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nmse_results = {penalty: [] for penalty in penalties}\nf1_results = {penalty: [] for penalty in penalties}\n\n\n# Fit models across regularization path\nfor i, (penalty, model) in enumerate(zip(penalties, models)):\n    print(f\"Fitting {penalty} penalty across {len(alphas)} regularization values...\")\n    for alpha_idx, alpha in enumerate(alphas):\n        print(\n            f\"  alpha {alpha_idx+1}/{len(alphas)}: \"\n            f\"lambda/lambda_max = {alpha/alpha_max:.1e}\",\n            end=\"\")\n\n        model.alpha = alpha\n        model.fit(S, mode='precomputed')\n\n        Theta_est = model.precision_\n        nmse = norm(Theta_est - Theta_true)**2 / norm(Theta_true)**2\n        f1_val = f1_score(Theta_est.flatten() != 0., Theta_true.flatten() != 0.)\n\n        nmse_results[penalty].append(nmse)\n        f1_results[penalty].append(f1_val)\n\n        print(f\"NMSE: {nmse:.3f}, F1: {f1_val:.3f}\")\n    print(f\"{penalty} penalty complete!\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axarr = plt.subplots(2, 1, sharex=True, figsize=([6.11, 3.91]),\n                          layout=\"constrained\")\ncmap = plt.get_cmap(\"tab10\")\nfor i, penalty in enumerate(penalties):\n\n    for j, ax in enumerate(axarr):\n\n        if j == 0:\n            metric = nmse_results\n            best_idx = np.argmin(metric[penalty])\n            ystop = np.min(metric[penalty])\n        else:\n            metric = f1_results\n            best_idx = np.argmax(metric[penalty])\n            ystop = np.max(metric[penalty])\n\n        ax.semilogx(alphas/alpha_max,\n                    metric[penalty],\n                    color=cmap(i),\n                    linewidth=2.,\n                    label=penalty)\n\n        ax.vlines(\n            x=alphas[best_idx] / alphas[0],\n            ymin=0,\n            ymax=ystop,\n            linestyle='--',\n            color=cmap(i))\n        line = ax.plot(\n            [alphas[best_idx] / alphas[0]],\n            0,\n            clip_on=False,\n            marker='X',\n            color=cmap(i),\n            markersize=12)\n\n        ax.grid(which='both', alpha=0.9)\n\naxarr[0].legend(fontsize=14)\naxarr[0].set_title(f\"{p=},{n=}\", fontsize=18)\naxarr[0].set_ylabel(\"NMSE\", fontsize=18)\naxarr[1].set_ylabel(\"F1 score\", fontsize=18)\n_ = axarr[1].set_xlabel(r\"$\\lambda / \\lambda_\\mathrm{{max}}$\",  fontsize=18)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results summary\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Performance at optimal regularization:\")\nprint(\"-\" * 50)\n\nfor penalty in penalties:\n    best_nmse = min(nmse_results[penalty])\n    best_f1 = max(f1_results[penalty])\n    print(f\"{penalty:>4}: NMSE = {best_nmse:.3f}, F1 = {best_f1:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Metrics explanation:**\n\n* **NMSE (Normalized Mean Square Error)**: Measures reconstruction accuracy\n  of the precision matrix. Lower values = better reconstruction.\n* **F1 Score**: Measures sparsity pattern recovery (correctly identifying\n  which entries are zero/non-zero). Higher values = better sparsity.\n\n**Key finding**: Non-convex penalties achieve significantly\nbetter sparsity recovery (F1 score) while maintaining\ncompetitive reconstruction accuracy (NMSE).\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}