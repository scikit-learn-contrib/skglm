{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Comparison of lifelines with skglm for survival analysis\nThis example shows that ``skglm`` fits a Cox model exactly as ``lifelines`` but with\nx100 less time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data\n\nLet's first generate synthetic data on which to run the Cox estimator,\nusing ``skglm`` data utils.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skglm.utils.data import make_dummy_survival_data\n\nn_samples, n_features = 500, 100\ntm, s, X = make_dummy_survival_data(\n    n_samples, n_features,\n    normalize=True,\n    random_state=0\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The synthetic data has the following properties:\n\n* ``tm`` is the vector of occurrence times which follows a Weibull(1) distribution\n* ``s`` indicates the observations censorship and follows a Bernoulli(0.5) distribution\n* ``X`` is the matrix of predictors, generated using standard normal distribution with Toeplitz covariance.\n\nLet's inspect the data quickly:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(\n    1, 3,\n    figsize=(6, 2),\n    tight_layout=True,\n)\n\ndists = (tm, s, X[:, 5])\naxes_title = (\"times\", \"censorship\", \"fifth predictor\")\n\nfor idx, (dist, name) in enumerate(zip(dists, axes_title)):\n    axes[idx].hist(dist, bins=\"auto\")\n    axes[idx].set_title(name)\n\n_ = axes[0].set_ylabel(\"count\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fitting the Cox Estimator\n\nAfter generating the synthetic data, we can now fit a L1-regularized Cox estimator.\nTodo so, we need to combine a Cox datafit and a $\\ell_1$ penalty\nand solve the resulting problem using skglm Proximal Newton solver ``ProxNewton``.\nWe set the intensity of the $\\ell_1$ regularization to ``alpha=1e-2``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skglm.datafits import Cox\nfrom skglm.penalties import L1\nfrom skglm.solvers import ProxNewton\n\nfrom skglm.utils.jit_compilation import compiled_clone\n\n# regularization intensity\nalpha = 1e-2\n\n# skglm internals: init datafit and penalty\ndatafit = compiled_clone(Cox())\npenalty = compiled_clone(L1(alpha))\n\ndatafit.initialize(X, (tm, s))\n\n# init solver\nsolver = ProxNewton(fit_intercept=False, max_iter=50)\n\n# solve the problem\nw_sk = solver.solve(X, (tm, s), datafit, penalty)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this data a regularization value a relatively sparse solution is found:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\n    \"Number of nonzero coefficients in solution: \"\n    f\"{(w_sk != 0).sum()} out of {len(w_sk)}.\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's solve the problem with ``lifelines`` through its ``CoxPHFitter``\nestimator and compare the objectives found by the two packages.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nfrom lifelines import CoxPHFitter\n\n# format data\nstacked_tm_s_X = np.hstack((tm[:, None], s[:, None], X))\ndf = pd.DataFrame(stacked_tm_s_X)\n\n# fit lifelines estimator\nlifelines_estimator = CoxPHFitter(penalizer=alpha, l1_ratio=1.).fit(\n    df,\n    duration_col=0,\n    event_col=1\n)\nw_ll = lifelines_estimator.params_.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check that both solvers find solutions having the same objective value:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "obj_sk = datafit.value((tm, s), w_sk, X @ w_sk) + penalty.value(w_sk)\nobj_ll = datafit.value((tm, s), w_ll, X @ w_ll) + penalty.value(w_ll)\n\nprint(f\"Objective skglm: {obj_sk:.6f}\")\nprint(f\"Objective lifelines: {obj_ll:.6f}\")\nprint(f\"Difference: {(obj_sk - obj_ll):.2e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can do the same to check how close the two solutions are.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"Euclidean distance between solutions: {np.linalg.norm(w_sk - w_ll):.3e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Timing comparison\n\nNow that we checked that both ``skglm`` and ``lifelines`` yield the same results,\nlet's compare their execution time. To get the evolution of the suboptimality\n(objective - optimal objective) we run both estimators with increasing number of\niterations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n# where to save records\nrecords = {\n    \"skglm\": {\"times\": [], \"objs\": []},\n    \"lifelines\": {\"times\": [], \"objs\": []},\n}\n\n# time skglm\nmax_runs = 20\nfor n_iter in range(1, max_runs + 1):\n    solver.max_iter = n_iter\n\n    start = time.perf_counter()\n    w = solver.solve(X, (tm, s), datafit, penalty)[0]\n    end = time.perf_counter()\n\n    records[\"skglm\"][\"objs\"].append(\n        datafit.value((tm, s), w, X @ w) + penalty.value(w)\n    )\n    records[\"skglm\"][\"times\"].append(end - start)\n\n# time lifelines\nmax_runs = 50\nfor n_iter in list(range(10)) + list(range(10, max_runs + 1, 5)):\n    start = time.perf_counter()\n    lifelines_estimator.fit(\n        df,\n        duration_col=0,\n        event_col=1,\n        fit_options={\"max_steps\": n_iter},\n    )\n    end = time.perf_counter()\n\n    w = lifelines_estimator.params_.values\n\n    records[\"lifelines\"][\"objs\"].append(\n        datafit.value((tm, s), w, X @ w) + penalty.value(w)\n    )\n    records[\"lifelines\"][\"times\"].append(end - start)\n\n\n# cast records as numpy array\nfor idx, label in enumerate((\"skglm\", \"lifelines\")):\n    for metric in (\"objs\", \"times\"):\n        records[label][metric] = np.asarray(records[label][metric])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, tight_layout=True, figsize=(6, 3))\nsolvers = (\"skglm\", \"lifelines\")\n\noptimal_obj = min(records[solver][\"objs\"].min() for solver in solvers)\n\n# plot evolution of suboptimality\nfor solver in solvers:\n    ax.semilogy(\n        records[solver][\"times\"],\n        records[solver][\"objs\"] - optimal_obj,\n        label=solver,\n        marker='o',\n    )\nax.legend()\nax.set_title(\"Time to fit a Cox model\")\n\nax.set_ylabel(\"objective suboptimality\")\n_ = ax.set_xlabel(\"time in seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "According to printed ratio, using ``skglm`` we get the same result as ``lifelines``\nwith more than x100 less time!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "speed_up = records[\"lifelines\"][\"times\"][-1] / records[\"skglm\"][\"times\"][-1]\nprint(f\"speed up ratio: {speed_up:.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Efron estimate\n\nThe previous results, namely closeness of solutions and timings,\ncan be extended to the case of handling tied observation with the Efron estimate.\n\nLet's start by generating data with tied observations. This can be achieved\nby passing in a ``with_ties=True`` to ``make_dummy_survival_data`` function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tm, s, X = make_dummy_survival_data(\n    n_samples, n_features,\n    normalize=True,\n    with_ties=True,\n    random_state=0\n)\n\n# check the data has tied observations\nprint(f\"Number of unique times {len(np.unique(tm))} out of {n_samples}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is straightforward to fit an $\\ell_1$ Cox estimator with the Efron estimate.\nWe only need to pass in ``use_efron=True`` to the ``Cox`` datafit.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ensure using Efron estimate\ndatafit = compiled_clone(Cox(use_efron=True))\ndatafit.initialize(X, (tm, s))\n\n# solve the problem\nsolver = ProxNewton(fit_intercept=False, max_iter=50)\nw_sk = solver.solve(X, (tm, s), datafit, penalty)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again a relatively sparse solution is found:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\n    \"Number of nonzero coefficients in solution: \"\n    f\"{(w_sk != 0).sum()} out of {len(w_sk)}.\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's do the same with ``lifelines`` and compare the results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# format data\nstacked_tm_s_X = np.hstack((tm[:, None], s[:, None], X))\ndf = pd.DataFrame(stacked_tm_s_X)\n\n# fit lifelines estimator on the new data\nlifelines_estimator = CoxPHFitter(penalizer=alpha, l1_ratio=1.).fit(\n    df,\n    duration_col=0,\n    event_col=1\n)\nw_ll = lifelines_estimator.params_.values\n\n# Check that both solvers find solutions with the same objective value\nobj_sk = datafit.value((tm, s), w_sk, X @ w_sk) + penalty.value(w_sk)\nobj_ll = datafit.value((tm, s), w_ll, X @ w_ll) + penalty.value(w_ll)\n\nprint(f\"Objective skglm: {obj_sk:.6f}\")\nprint(f\"Objective lifelines: {obj_ll:.6f}\")\nprint(f\"Difference: {(obj_sk - obj_ll):.2e}\")\n\n# Check that both solutions are close\nprint(f\"Euclidean distance between solutions: {np.linalg.norm(w_sk - w_ll):.3e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, let's compare the timings of both solvers\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# time skglm\nstart = time.perf_counter()\nsolver.solve(X, (tm, s), datafit, penalty)[0]\nend = time.perf_counter()\n\ntotal_time_skglm = end - start\n\n# time lifelines\nlifelines_estimator = CoxPHFitter(penalizer=alpha, l1_ratio=1.)\n\nstart = time.perf_counter()\nlifelines_estimator.fit(\n    df,\n    duration_col=0,\n    event_col=1\n)\nend = time.perf_counter()\n\ntotal_time_lifelines = end - start\n\n# deduce speed up ratio\nspeed_up = total_time_lifelines / total_time_skglm\nprint(f\"speed up ratio: {speed_up:.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As shown by the last print, we still preserve the x100 ratio speed up\neven for the Efron estimate.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}